{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Install mmsegmentation"
      ],
      "metadata": {
        "id": "cUs-Wg2GYAhh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qFLBek0yX0on",
        "outputId": "bcd420a6-2f50-49c7-d3b8-637918a55c7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openmim\n",
            "  Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click in /usr/local/lib/python3.10/dist-packages (from openmim) (8.1.7)\n",
            "Collecting colorama (from openmim)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting model-index (from openmim)\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Collecting opendatalab (from openmim)\n",
            "  Downloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from openmim) (1.5.3)\n",
            "Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.10/dist-packages (from openmim) (23.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openmim) (2.31.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim) (13.5.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim) (0.9.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (6.0.1)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (3.4.4)\n",
            "Collecting ordered-set (from model-index->openmim)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Collecting pycryptodome (from opendatalab->openmim)\n",
            "  Downloading pycryptodome-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatalab->openmim) (4.66.1)\n",
            "Collecting openxlab (from opendatalab->openmim)\n",
            "  Downloading openxlab-0.0.22-py3-none-any.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.3/300.3 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2023.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (1.23.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->openmim) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->openmim) (1.16.0)\n",
            "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim)\n",
            "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting requests (from openmim)\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rich (from openmim)\n",
            "  Downloading rich-13.4.2-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setuptools~=60.2.0 (from openxlab->opendatalab->openmim)\n",
            "  Downloading setuptools-60.2.0-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm (from opendatalab->openmim)\n",
            "  Downloading tqdm-4.65.2-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1 (from requests->openmim)\n",
            "  Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting crcmod>=1.7 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading aliyun_python_sdk_kms-2.16.1-py2.py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.8/70.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aliyun-python-sdk-core>=2.13.12 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading aliyun-python-sdk-core-2.13.36.tar.gz (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.5/440.5 kB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: cryptography>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (41.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (2.21)\n",
            "Building wheels for collected packages: oss2, aliyun-python-sdk-core, crcmod\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oss2: filename=oss2-2.17.0-py3-none-any.whl size=112371 sha256=e92832882a5ae894e2d4c7cf80090b7ad76dbb61b038884765ffafb08fcc4b8f\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/04/7b/7e61b8157fdf211c5131375240d0d86ca82e2a88ead9672c88\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.13.36-py3-none-any.whl size=533190 sha256=bfd4c8d6cdf7a1f412cfa4b13b515757e7945e035a2c31c9f76da18ccb5bdaea\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/f4/0e/87c534857132bd3bd2c4465c0b15b4db650cf6c15a876bda34\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31403 sha256=2fe82f4d3dc639e7b3e9a374b75502a2bfe488db3d52b4a5c298dbc835855c1d\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "Successfully built oss2 aliyun-python-sdk-core crcmod\n",
            "Installing collected packages: crcmod, urllib3, tqdm, setuptools, pycryptodome, ordered-set, jmespath, colorama, rich, requests, model-index, aliyun-python-sdk-core, aliyun-python-sdk-kms, oss2, openxlab, opendatalab, openmim\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.4\n",
            "    Uninstalling urllib3-2.0.4:\n",
            "      Successfully uninstalled urllib3-2.0.4\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.1\n",
            "    Uninstalling tqdm-4.66.1:\n",
            "      Successfully uninstalled tqdm-4.66.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.5.2\n",
            "    Uninstalling rich-13.5.2:\n",
            "      Successfully uninstalled rich-13.5.2\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "cvxpy 1.3.2 requires setuptools>65.5.1, but you have setuptools 60.2.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.28.2 which is incompatible.\n",
            "yfinance 0.2.28 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aliyun-python-sdk-core-2.13.36 aliyun-python-sdk-kms-2.16.1 colorama-0.4.6 crcmod-1.7 jmespath-0.10.0 model-index-0.1.11 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.22 ordered-set-4.1.0 oss2-2.17.0 pycryptodome-3.18.0 requests-2.28.2 rich-13.4.2 setuptools-60.2.0 tqdm-4.65.2 urllib3-1.26.16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources",
                  "setuptools"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/index.html\n",
            "Collecting mmengine\n",
            "  Downloading mmengine-0.8.4-py3-none-any.whl (437 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.5/437.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting addict (from mmengine)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmengine) (1.23.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmengine) (6.0.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine) (2.3.0)\n",
            "Collecting yapf (from mmengine)\n",
            "  Downloading yapf-0.40.1-py3-none-any.whl (250 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.3/250.3 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmengine) (4.8.0.76)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine) (2.16.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine) (6.8.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine) (3.10.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmengine) (3.16.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine) (1.16.0)\n",
            "Installing collected packages: addict, yapf, mmengine\n",
            "Successfully installed addict-2.4.0 mmengine-0.8.4 yapf-0.40.1\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/index.html\n",
            "Collecting mmcv>=2.0.0\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/mmcv-2.0.1-cp310-cp310-manylinux1_x86_64.whl (74.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0) (2.4.0)\n",
            "Requirement already satisfied: mmengine>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0) (0.8.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0) (23.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0) (9.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0) (6.0.1)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0) (0.40.1)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0) (4.8.0.76)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv>=2.0.0) (3.7.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv>=2.0.0) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv>=2.0.0) (2.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv>=2.0.0) (6.8.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv>=2.0.0) (3.10.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv>=2.0.0) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmcv>=2.0.0) (3.16.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.3.0->mmcv>=2.0.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.3.0->mmcv>=2.0.0) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.3.0->mmcv>=2.0.0) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.3.0->mmcv>=2.0.0) (1.16.0)\n",
            "Installing collected packages: mmcv\n",
            "Successfully installed mmcv-2.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip3 install openmim\n",
        "!mim install mmengine\n",
        "!mim install \"mmcv>=2.0.0\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/open-mmlab/mmsegmentation.git\n",
        "%cd mmsegmentation\n",
        "!git checkout main\n",
        "!pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6KRgm9fX13z",
        "outputId": "f0324609-0fa2-43de-9d8a-5cdaadd0826a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mmsegmentation'...\n",
            "remote: Enumerating objects: 15927, done.\u001b[K\n",
            "remote: Counting objects: 100% (294/294), done.\u001b[K\n",
            "remote: Compressing objects: 100% (228/228), done.\u001b[K\n",
            "remote: Total 15927 (delta 110), reused 177 (delta 59), pack-reused 15633\u001b[K\n",
            "Receiving objects: 100% (15927/15927), 22.61 MiB | 1.41 MiB/s, done.\n",
            "Resolving deltas: 100% (11123/11123), done.\n",
            "/content/mmsegmentation\n",
            "Already on 'main'\n",
            "Your branch is up to date with 'origin/main'.\n",
            "Obtaining file:///content/mmsegmentation\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmsegmentation==1.1.1) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmsegmentation==1.1.1) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmsegmentation==1.1.1) (23.1)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from mmsegmentation==1.1.1) (3.8.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmsegmentation==1.1.1) (1.10.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==1.1.1) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==1.1.1) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==1.1.1) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==1.1.1) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==1.1.1) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==1.1.1) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==1.1.1) (2.8.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable->mmsegmentation==1.1.1) (0.2.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmsegmentation==1.1.1) (1.16.0)\n",
            "Installing collected packages: mmsegmentation\n",
            "  Running setup.py develop for mmsegmentation\n",
            "Successfully installed mmsegmentation-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mmseg\n",
        "print(mmseg.__version__)\n",
        "# Example output: 1.0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNIAGwkjX3vF",
        "outputId": "93407190-2faf-4e6b-c08d-97f38334b5af"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install cityscapesscripts module\n",
        "!python -m pip install cityscapesscripts"
      ],
      "metadata": {
        "id": "JadArYimogvw"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load dataset"
      ],
      "metadata": {
        "id": "-nyuF1R1YE4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install imagemagick"
      ],
      "metadata": {
        "id": "bmDQFjVHYFdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ..\n",
        "!cp drive/MyDrive/Volkswagen/*.zip .\n",
        "!mkdir data\n",
        "!unzip leftImg8bit_trainvaltest.zip -d data/leftImg8bit_trainvaltest\n",
        "!unzip gtFine_trainvaltest.zip -d data/gtFine_trainvaltest"
      ],
      "metadata": {
        "id": "EqSwA6PUYH2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p compressed/\n",
        "!touch compress.sh\n",
        "!bash compress.sh 75%\n",
        "!bash compress.sh 25%"
      ],
      "metadata": {
        "id": "hxHluMbtYJfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### load compressed images"
      ],
      "metadata": {
        "id": "nPzNublDhlW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp drive/MyDrive/Volkswagen/*.zip .\n",
        "!cp drive/MyDrive/Volkswagen/deeplabv3_r50b-d8_769x769_80k_cityscapes_20201225_155404-87fb0cf4.pth ."
      ],
      "metadata": {
        "id": "gdCe8oqmhHl5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip compressed25.zip\n",
        "!unzip compressed75.zip"
      ],
      "metadata": {
        "id": "auSmSGdohrnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare dataset - 25% compression"
      ],
      "metadata": {
        "id": "NreKSpKEmO1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp drive/MyDrive/Volkswagen/gtFine_trainvaltest.zip .\n",
        "!unzip gtFine_trainvaltest"
      ],
      "metadata": {
        "id": "hEDRSV4jlmin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 25% quality\n",
        "!mkdir -p mmsegmentation/data/cityscapes\n",
        "!mv compressed_25% leftImg8bit\n",
        "!mv leftImg8bit mmsegmentation/data/cityscapes\n",
        "!mv gtFine/ mmsegmentation/data/cityscapes"
      ],
      "metadata": {
        "id": "bjdOFtTymkKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --nproc means 8 process for conversion, which could be omitted as well.\n",
        "!python mmsegmentation/tools/dataset_converters/cityscapes.py mmsegmentation/data/cityscapes --nproc 8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9syCVTvHn86q",
        "outputId": "1fd2b3c7-e2bc-4a89-f2b3-1af7f59a3f0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[>>] 5000/5000, 32.2 task/s, elapsed: 155s, ETA:     0s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference using the checkpoint - 25% compression"
      ],
      "metadata": {
        "id": "-OyJzVoNpi1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd mmsegmentation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bvIJiCEq2GJ",
        "outputId": "dbc4e517-abb0-4e93-ce1f-53b430931762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mmsegmentation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python tools/test.py \\\n",
        "     configs/deeplabv3/deeplabv3_r50-d8_4xb2-80k_cityscapes-769x769.py \\\n",
        "     ../deeplabv3_r50b-d8_769x769_80k_cityscapes_20201225_155404-87fb0cf4.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaRiz2Ynpv6r",
        "outputId": "9cbbaac9-4d45-4070-89fe-fe8d064f15fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "08/28 08:24:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 1390445367\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.1+cu118\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.8\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.7\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.2+cu118\n",
            "    OpenCV: 4.8.0\n",
            "    MMEngine: 0.8.4\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 1390445367\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "08/28 08:24:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "crop_size = (\n",
            "    769,\n",
            "    769,\n",
            ")\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ],\n",
            "    pad_val=0,\n",
            "    seg_pad_val=255,\n",
            "    size=(\n",
            "        769,\n",
            "        769,\n",
            "    ),\n",
            "    std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ],\n",
            "    type='SegDataPreProcessor')\n",
            "data_root = 'data/cityscapes/'\n",
            "dataset_type = 'CityscapesDataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(by_epoch=False, interval=100, type='CheckpointHook'),\n",
            "    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(draw=True, interval=100, type='SegVisualizationHook'))\n",
            "default_scope = 'mmseg'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_ratios = [\n",
            "    0.5,\n",
            "    0.75,\n",
            "    1.0,\n",
            "    1.25,\n",
            "    1.5,\n",
            "    1.75,\n",
            "]\n",
            "launcher = 'none'\n",
            "load_from = '../deeplabv3_r50b-d8_769x769_80k_cityscapes_20201225_155404-87fb0cf4.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=False)\n",
            "model = dict(\n",
            "    auxiliary_head=dict(\n",
            "        align_corners=True,\n",
            "        channels=256,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=1024,\n",
            "        in_index=2,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='SyncBN'),\n",
            "        num_classes=19,\n",
            "        num_convs=1,\n",
            "        type='FCNHead'),\n",
            "    backbone=dict(\n",
            "        contract_dilation=True,\n",
            "        depth=50,\n",
            "        dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            2,\n",
            "            4,\n",
            "        ),\n",
            "        norm_cfg=dict(requires_grad=True, type='SyncBN'),\n",
            "        norm_eval=False,\n",
            "        num_stages=4,\n",
            "        out_indices=(\n",
            "            0,\n",
            "            1,\n",
            "            2,\n",
            "            3,\n",
            "        ),\n",
            "        strides=(\n",
            "            1,\n",
            "            2,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        style='pytorch',\n",
            "        type='ResNetV1c'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_val=0,\n",
            "        seg_pad_val=255,\n",
            "        size=(\n",
            "            769,\n",
            "            769,\n",
            "        ),\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='SegDataPreProcessor'),\n",
            "    decode_head=dict(\n",
            "        align_corners=True,\n",
            "        channels=512,\n",
            "        dilations=(\n",
            "            1,\n",
            "            12,\n",
            "            24,\n",
            "            36,\n",
            "        ),\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=2048,\n",
            "        in_index=3,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='SyncBN'),\n",
            "        num_classes=19,\n",
            "        type='ASPPHead'),\n",
            "    pretrained='open-mmlab://resnet50_v1c',\n",
            "    test_cfg=dict(crop_size=(\n",
            "        769,\n",
            "        769,\n",
            "    ), mode='slide', stride=(\n",
            "        513,\n",
            "        513,\n",
            "    )),\n",
            "    train_cfg=dict(),\n",
            "    type='EncoderDecoder')\n",
            "norm_cfg = dict(requires_grad=True, type='SyncBN')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=None,\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=False,\n",
            "        end=80000,\n",
            "        eta_min=0.0001,\n",
            "        power=0.9,\n",
            "        type='PolyLR'),\n",
            "]\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        data_prefix=dict(\n",
            "            img_path='leftImg8bit/val', seg_map_path='gtFine/val'),\n",
            "        data_root='data/cityscapes/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                2049,\n",
            "                1025,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='CityscapesDataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mIoU',\n",
            "    ], type='IoUMetric')\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        2049,\n",
            "        1025,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "train_cfg = dict(max_iters=500, type='IterBasedTrainLoop', val_interval=500)\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    dataset=dict(\n",
            "        data_prefix=dict(\n",
            "            img_path='leftImg8bit/train', seg_map_path='gtFine/train'),\n",
            "        data_root='data/cityscapes/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(\n",
            "                keep_ratio=True,\n",
            "                ratio_range=(\n",
            "                    0.5,\n",
            "                    2.0,\n",
            "                ),\n",
            "                scale=(\n",
            "                    2049,\n",
            "                    1025,\n",
            "                ),\n",
            "                type='RandomResize'),\n",
            "            dict(\n",
            "                cat_max_ratio=0.75, crop_size=(\n",
            "                    769,\n",
            "                    769,\n",
            "                ), type='RandomCrop'),\n",
            "            dict(prob=0.5, type='RandomFlip'),\n",
            "            dict(type='PhotoMetricDistortion'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='CityscapesDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(\n",
            "        keep_ratio=True,\n",
            "        ratio_range=(\n",
            "            0.5,\n",
            "            2.0,\n",
            "        ),\n",
            "        scale=(\n",
            "            2049,\n",
            "            1025,\n",
            "        ),\n",
            "        type='RandomResize'),\n",
            "    dict(cat_max_ratio=0.75, crop_size=(\n",
            "        769,\n",
            "        769,\n",
            "    ), type='RandomCrop'),\n",
            "    dict(prob=0.5, type='RandomFlip'),\n",
            "    dict(type='PhotoMetricDistortion'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "tta_model = dict(type='SegTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
            "            ],\n",
            "            [\n",
            "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
            "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='LoadAnnotations'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        data_prefix=dict(\n",
            "            img_path='leftImg8bit/val', seg_map_path='gtFine/val'),\n",
            "        data_root='data/cityscapes/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                2049,\n",
            "                1025,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='CityscapesDataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mIoU',\n",
            "    ], type='IoUMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='SegLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/deeplabv3_r50-d8_4xb2-80k_cityscapes-769x769'\n",
            "\n",
            "/content/mmsegmentation/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use \"init_cfg\" instead\n",
            "  warnings.warn('DeprecationWarning: pretrained is a deprecated, '\n",
            "/content/mmsegmentation/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
            "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
            "/content/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
            "  warnings.warn(\n",
            "08/28 08:24:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "08/28 08:24:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "08/28 08:24:19 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
            "Loads checkpoint by local backend from path: ../deeplabv3_r50b-d8_769x769_80k_cityscapes_20201225_155404-87fb0cf4.pth\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: backbone.conv1.weight, backbone.bn1.weight, backbone.bn1.bias, backbone.bn1.running_mean, backbone.bn1.running_var, backbone.bn1.num_batches_tracked\n",
            "\n",
            "missing keys in source state_dict: backbone.stem.0.weight, backbone.stem.1.weight, backbone.stem.1.bias, backbone.stem.1.running_mean, backbone.stem.1.running_var, backbone.stem.3.weight, backbone.stem.4.weight, backbone.stem.4.bias, backbone.stem.4.running_mean, backbone.stem.4.running_var, backbone.stem.6.weight, backbone.stem.7.weight, backbone.stem.7.bias, backbone.stem.7.running_mean, backbone.stem.7.running_var\n",
            "\n",
            "08/28 08:24:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from ../deeplabv3_r50b-d8_769x769_80k_cityscapes_20201225_155404-87fb0cf4.pth\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "08/28 08:26:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [ 50/500]    eta: 0:21:35  time: 2.5794  data_time: 0.0095  memory: 8906  \n",
            "08/28 08:28:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [100/500]    eta: 0:18:06  time: 2.5525  data_time: 0.0099  memory: 905  \n",
            "08/28 08:31:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [150/500]    eta: 0:15:38  time: 2.5561  data_time: 0.0101  memory: 905  \n",
            "08/28 08:33:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [200/500]    eta: 0:13:14  time: 2.5602  data_time: 0.0114  memory: 905  \n",
            "08/28 08:35:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [250/500]    eta: 0:10:58  time: 2.5602  data_time: 0.0113  memory: 905  \n",
            "08/28 08:37:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [300/500]    eta: 0:08:44  time: 2.5567  data_time: 0.0093  memory: 905  \n",
            "08/28 08:39:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [350/500]    eta: 0:06:32  time: 2.5622  data_time: 0.0097  memory: 905  \n",
            "08/28 08:41:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [400/500]    eta: 0:04:20  time: 2.5523  data_time: 0.0109  memory: 905  \n",
            "08/28 08:43:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [450/500]    eta: 0:02:10  time: 2.5589  data_time: 0.0093  memory: 905  \n",
            "08/28 08:46:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [500/500]    eta: 0:00:00  time: 2.5550  data_time: 0.0066  memory: 905  \n",
            "08/28 08:46:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
            "08/28 08:46:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "+---------------+-------+-------+\n",
            "|     Class     |  IoU  |  Acc  |\n",
            "+---------------+-------+-------+\n",
            "|      road     | 55.47 | 61.51 |\n",
            "|    sidewalk   |  0.63 |  0.64 |\n",
            "|    building   | 29.55 | 40.69 |\n",
            "|      wall     |  0.93 |  5.03 |\n",
            "|     fence     |  0.66 |  0.83 |\n",
            "|      pole     |  1.64 |  1.7  |\n",
            "| traffic light |  0.0  |  0.0  |\n",
            "|  traffic sign |  0.0  |  0.0  |\n",
            "|   vegetation  | 19.48 | 29.38 |\n",
            "|    terrain    |  0.0  |  0.0  |\n",
            "|      sky      |  1.95 | 23.54 |\n",
            "|     person    |  0.1  |  0.1  |\n",
            "|     rider     |  0.0  |  0.0  |\n",
            "|      car      |  0.03 |  0.03 |\n",
            "|     truck     |  0.0  |  0.0  |\n",
            "|      bus      |  0.0  |  0.0  |\n",
            "|     train     |  0.0  |  0.0  |\n",
            "|   motorcycle  |  0.0  |  0.0  |\n",
            "|    bicycle    |  0.0  |  0.0  |\n",
            "+---------------+-------+-------+\n",
            "08/28 08:46:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [500/500]    aAcc: 38.0700  mIoU: 5.8100  mAcc: 8.6000  data_time: 0.0213  time: 2.6003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bonus - 25% compression"
      ],
      "metadata": {
        "id": "pzsZFHc4H9Rb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python tools/train.py \\\n",
        "     configs/deeplabv3/deeplabv3_r50-d8_4xb2-80k_cityscapes-769x769.py \\\n",
        "     --cfg-options load_from=../deeplabv3_r50b-d8_769x769_80k_cityscapes_20201225_155404-87fb0cf4.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPTcy7mhIM7b",
        "outputId": "461efd59-e31a-430a-eeea-0703ac490c3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "08/28 09:04:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 1825581003\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.1+cu118\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.8\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.7\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.2+cu118\n",
            "    OpenCV: 4.8.0\n",
            "    MMEngine: 0.8.4\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 1825581003\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "08/28 09:04:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "crop_size = (\n",
            "    769,\n",
            "    769,\n",
            ")\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ],\n",
            "    pad_val=0,\n",
            "    seg_pad_val=255,\n",
            "    size=(\n",
            "        769,\n",
            "        769,\n",
            "    ),\n",
            "    std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ],\n",
            "    type='SegDataPreProcessor')\n",
            "data_root = 'data/cityscapes/'\n",
            "dataset_type = 'CityscapesDataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(by_epoch=False, interval=100, type='CheckpointHook'),\n",
            "    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='SegVisualizationHook'))\n",
            "default_scope = 'mmseg'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_ratios = [\n",
            "    0.5,\n",
            "    0.75,\n",
            "    1.0,\n",
            "    1.25,\n",
            "    1.5,\n",
            "    1.75,\n",
            "]\n",
            "launcher = 'none'\n",
            "load_from = '../deeplabv3_r50b-d8_769x769_80k_cityscapes_20201225_155404-87fb0cf4.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=False)\n",
            "model = dict(\n",
            "    auxiliary_head=dict(\n",
            "        align_corners=True,\n",
            "        channels=256,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=1024,\n",
            "        in_index=2,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='SyncBN'),\n",
            "        num_classes=19,\n",
            "        num_convs=1,\n",
            "        type='FCNHead'),\n",
            "    backbone=dict(\n",
            "        contract_dilation=True,\n",
            "        depth=50,\n",
            "        dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            2,\n",
            "            4,\n",
            "        ),\n",
            "        norm_cfg=dict(requires_grad=True, type='SyncBN'),\n",
            "        norm_eval=False,\n",
            "        num_stages=4,\n",
            "        out_indices=(\n",
            "            0,\n",
            "            1,\n",
            "            2,\n",
            "            3,\n",
            "        ),\n",
            "        strides=(\n",
            "            1,\n",
            "            2,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        style='pytorch',\n",
            "        type='ResNetV1c'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_val=0,\n",
            "        seg_pad_val=255,\n",
            "        size=(\n",
            "            769,\n",
            "            769,\n",
            "        ),\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='SegDataPreProcessor'),\n",
            "    decode_head=dict(\n",
            "        align_corners=True,\n",
            "        channels=512,\n",
            "        dilations=(\n",
            "            1,\n",
            "            12,\n",
            "            24,\n",
            "            36,\n",
            "        ),\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=2048,\n",
            "        in_index=3,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='SyncBN'),\n",
            "        num_classes=19,\n",
            "        type='ASPPHead'),\n",
            "    pretrained='open-mmlab://resnet50_v1c',\n",
            "    test_cfg=dict(crop_size=(\n",
            "        769,\n",
            "        769,\n",
            "    ), mode='slide', stride=(\n",
            "        513,\n",
            "        513,\n",
            "    )),\n",
            "    train_cfg=dict(),\n",
            "    type='EncoderDecoder')\n",
            "norm_cfg = dict(requires_grad=True, type='SyncBN')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=None,\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=False,\n",
            "        end=80000,\n",
            "        eta_min=0.0001,\n",
            "        power=0.9,\n",
            "        type='PolyLR'),\n",
            "]\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        data_prefix=dict(\n",
            "            img_path='leftImg8bit/val', seg_map_path='gtFine/val'),\n",
            "        data_root='data/cityscapes/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                2049,\n",
            "                1025,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='CityscapesDataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mIoU',\n",
            "    ], type='IoUMetric')\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        2049,\n",
            "        1025,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "train_cfg = dict(max_iters=500, type='IterBasedTrainLoop', val_interval=500)\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    dataset=dict(\n",
            "        data_prefix=dict(\n",
            "            img_path='leftImg8bit/train', seg_map_path='gtFine/train'),\n",
            "        data_root='data/cityscapes/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(\n",
            "                keep_ratio=True,\n",
            "                ratio_range=(\n",
            "                    0.5,\n",
            "                    2.0,\n",
            "                ),\n",
            "                scale=(\n",
            "                    2049,\n",
            "                    1025,\n",
            "                ),\n",
            "                type='RandomResize'),\n",
            "            dict(\n",
            "                cat_max_ratio=0.75, crop_size=(\n",
            "                    769,\n",
            "                    769,\n",
            "                ), type='RandomCrop'),\n",
            "            dict(prob=0.5, type='RandomFlip'),\n",
            "            dict(type='PhotoMetricDistortion'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='CityscapesDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(\n",
            "        keep_ratio=True,\n",
            "        ratio_range=(\n",
            "            0.5,\n",
            "            2.0,\n",
            "        ),\n",
            "        scale=(\n",
            "            2049,\n",
            "            1025,\n",
            "        ),\n",
            "        type='RandomResize'),\n",
            "    dict(cat_max_ratio=0.75, crop_size=(\n",
            "        769,\n",
            "        769,\n",
            "    ), type='RandomCrop'),\n",
            "    dict(prob=0.5, type='RandomFlip'),\n",
            "    dict(type='PhotoMetricDistortion'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "tta_model = dict(type='SegTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
            "            ],\n",
            "            [\n",
            "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
            "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='LoadAnnotations'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        data_prefix=dict(\n",
            "            img_path='leftImg8bit/val', seg_map_path='gtFine/val'),\n",
            "        data_root='data/cityscapes/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                2049,\n",
            "                1025,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='CityscapesDataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mIoU',\n",
            "    ], type='IoUMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='SegLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/deeplabv3_r50-d8_4xb2-80k_cityscapes-769x769'\n",
            "\n",
            "/content/mmsegmentation/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use \"init_cfg\" instead\n",
            "  warnings.warn('DeprecationWarning: pretrained is a deprecated, '\n",
            "/content/mmsegmentation/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
            "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
            "/content/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
            "  warnings.warn(\n",
            "08/28 09:04:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "/content/mmsegmentation/mmseg/engine/hooks/visualization_hook.py:61: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
            "  warnings.warn('The draw is False, it means that the '\n",
            "08/28 09:04:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "08/28 09:04:28 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
            "08/28 09:04:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: open-mmlab://resnet50_v1c\n",
            "08/28 09:04:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by openmmlab backend from path: open-mmlab://resnet50_v1c\n",
            "08/28 09:04:29 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: fc.weight, fc.bias\n",
            "\n",
            "Loads checkpoint by local backend from path: ../deeplabv3_r50b-d8_769x769_80k_cityscapes_20201225_155404-87fb0cf4.pth\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: backbone.conv1.weight, backbone.bn1.weight, backbone.bn1.bias, backbone.bn1.running_mean, backbone.bn1.running_var, backbone.bn1.num_batches_tracked\n",
            "\n",
            "missing keys in source state_dict: backbone.stem.0.weight, backbone.stem.1.weight, backbone.stem.1.bias, backbone.stem.1.running_mean, backbone.stem.1.running_var, backbone.stem.3.weight, backbone.stem.4.weight, backbone.stem.4.bias, backbone.stem.4.running_mean, backbone.stem.4.running_var, backbone.stem.6.weight, backbone.stem.7.weight, backbone.stem.7.bias, backbone.stem.7.running_mean, backbone.stem.7.running_var\n",
            "\n",
            "08/28 09:04:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from ../deeplabv3_r50b-d8_769x769_80k_cityscapes_20201225_155404-87fb0cf4.pth\n",
            "08/28 09:04:30 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "08/28 09:04:30 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "08/28 09:04:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /content/mmsegmentation/work_dirs/deeplabv3_r50-d8_4xb2-80k_cityscapes-769x769.\n",
            "08/28 09:07:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 50/500]  lr: 9.9945e-03  eta: 0:30:03  time: 2.2291  data_time: 0.0077  memory: 11043  loss: 2.2059  decode.loss_ce: 1.5340  decode.acc_seg: 64.4239  aux.loss_ce: 0.6718  aux.acc_seg: 59.7187\n",
            "08/28 09:09:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [100/500]  lr: 9.9890e-03  eta: 0:20:57  time: 2.2754  data_time: 0.0085  memory: 6561  loss: 1.7459  decode.loss_ce: 1.1996  decode.acc_seg: 72.0714  aux.loss_ce: 0.5463  aux.acc_seg: 59.7551\n",
            "08/28 09:09:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 100 iterations\n",
            "08/28 09:11:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [150/500]  lr: 9.9834e-03  eta: 0:16:52  time: 2.2888  data_time: 0.0079  memory: 6561  loss: 1.4409  decode.loss_ce: 0.9575  decode.acc_seg: 57.1115  aux.loss_ce: 0.4834  aux.acc_seg: 51.1684\n",
            "08/28 09:13:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [200/500]  lr: 9.9778e-03  eta: 0:13:42  time: 2.2912  data_time: 0.0073  memory: 6560  loss: 1.5828  decode.loss_ce: 1.0778  decode.acc_seg: 72.4496  aux.loss_ce: 0.5050  aux.acc_seg: 64.8459\n",
            "08/28 09:13:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 200 iterations\n",
            "08/28 09:15:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [250/500]  lr: 9.9723e-03  eta: 0:11:06  time: 2.2832  data_time: 0.0075  memory: 6561  loss: 1.2514  decode.loss_ce: 0.8331  decode.acc_seg: 74.5097  aux.loss_ce: 0.4184  aux.acc_seg: 69.4841\n",
            "08/28 09:17:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [300/500]  lr: 9.9667e-03  eta: 0:08:40  time: 2.2865  data_time: 0.0079  memory: 6560  loss: 1.5576  decode.loss_ce: 1.0678  decode.acc_seg: 71.2951  aux.loss_ce: 0.4898  aux.acc_seg: 59.3659\n",
            "08/28 09:17:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 300 iterations\n",
            "08/28 09:19:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [350/500]  lr: 9.9611e-03  eta: 0:06:25  time: 2.2975  data_time: 0.0080  memory: 6561  loss: 1.1168  decode.loss_ce: 0.7525  decode.acc_seg: 58.3454  aux.loss_ce: 0.3643  aux.acc_seg: 57.7425\n",
            "08/28 09:21:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [400/500]  lr: 9.9555e-03  eta: 0:04:13  time: 2.2953  data_time: 0.0081  memory: 6561  loss: 1.5360  decode.loss_ce: 1.0793  decode.acc_seg: 62.1194  aux.loss_ce: 0.4567  aux.acc_seg: 54.1213\n",
            "08/28 09:21:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 400 iterations\n",
            "08/28 09:23:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [450/500]  lr: 9.9500e-03  eta: 0:02:05  time: 2.2905  data_time: 0.0078  memory: 6561  loss: 1.5091  decode.loss_ce: 1.0677  decode.acc_seg: 65.9911  aux.loss_ce: 0.4414  aux.acc_seg: 53.5920\n",
            "08/28 09:25:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [500/500]  lr: 9.9444e-03  eta: 0:00:00  time: 2.2899  data_time: 0.0075  memory: 6561  loss: 1.0222  decode.loss_ce: 0.6796  decode.acc_seg: 78.7016  aux.loss_ce: 0.3426  aux.acc_seg: 73.3585\n",
            "08/28 09:25:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 500 iterations\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "08/28 09:27:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [ 50/500]    eta: 0:22:40  time: 2.5875  data_time: 0.0068  memory: 9167  \n",
            "08/28 09:29:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/500]    eta: 0:18:42  time: 2.5880  data_time: 0.0069  memory: 1166  \n",
            "08/28 09:32:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [150/500]    eta: 0:15:57  time: 2.5907  data_time: 0.0072  memory: 1166  \n",
            "08/28 09:34:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [200/500]    eta: 0:13:29  time: 2.5767  data_time: 0.0075  memory: 1166  \n",
            "08/28 09:36:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [250/500]    eta: 0:11:08  time: 2.5883  data_time: 0.0066  memory: 1166  \n",
            "08/28 09:38:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [300/500]    eta: 0:08:52  time: 2.5921  data_time: 0.0063  memory: 1166  \n",
            "08/28 09:40:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [350/500]    eta: 0:06:37  time: 2.5855  data_time: 0.0074  memory: 1166  \n",
            "08/28 09:42:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [400/500]    eta: 0:04:24  time: 2.5891  data_time: 0.0074  memory: 1166  \n",
            "08/28 09:45:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [450/500]    eta: 0:02:11  time: 2.5858  data_time: 0.0070  memory: 1166  \n",
            "08/28 09:47:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [500/500]    eta: 0:00:00  time: 2.5826  data_time: 0.0068  memory: 1166  \n",
            "08/28 09:47:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
            "08/28 09:47:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "+---------------+-------+-------+\n",
            "|     Class     |  IoU  |  Acc  |\n",
            "+---------------+-------+-------+\n",
            "|      road     | 83.59 | 92.31 |\n",
            "|    sidewalk   | 31.96 | 52.51 |\n",
            "|    building   | 64.76 | 83.39 |\n",
            "|      wall     |  0.0  |  0.0  |\n",
            "|     fence     |  0.0  |  0.0  |\n",
            "|      pole     |  3.17 |  3.3  |\n",
            "| traffic light |  0.0  |  0.0  |\n",
            "|  traffic sign |  0.0  |  0.0  |\n",
            "|   vegetation  | 74.05 | 86.29 |\n",
            "|    terrain    |  1.8  |  1.81 |\n",
            "|      sky      |  66.6 | 95.68 |\n",
            "|     person    |  0.08 |  0.08 |\n",
            "|     rider     |  0.0  |  0.0  |\n",
            "|      car      | 44.28 | 67.43 |\n",
            "|     truck     |  0.0  |  0.0  |\n",
            "|      bus      |  0.0  |  0.0  |\n",
            "|     train     |  0.0  |  0.0  |\n",
            "|   motorcycle  |  0.0  |  0.0  |\n",
            "|    bicycle    |  0.0  |  0.0  |\n",
            "+---------------+-------+-------+\n",
            "08/28 09:47:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [500/500]    aAcc: 78.4900  mIoU: 19.4900  mAcc: 25.4100  data_time: 0.0096  time: 2.6302\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference using the checkpoint - 75% compression"
      ],
      "metadata": {
        "id": "B1xbi2L5p3Ze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python tools/test.py \\\n",
        "     configs/deeplabv3/deeplabv3_r50-d8_4xb2-80k_cityscapes-769x769.py \\\n",
        "     deeplabv3_r50b-d8_769x769_80k_cityscapes_20201225_155404-87fb0cf4.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfx67vWsrvIn",
        "outputId": "cc2fd8d8-715a-4547-d376-d40814f28e90"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "08/28 12:17:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 1119155046\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.1+cu118\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.8\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.7\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.2+cu118\n",
            "    OpenCV: 4.8.0\n",
            "    MMEngine: 0.8.4\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 1119155046\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "08/28 12:17:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "crop_size = (\n",
            "    769,\n",
            "    769,\n",
            ")\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ],\n",
            "    pad_val=0,\n",
            "    seg_pad_val=255,\n",
            "    size=(\n",
            "        769,\n",
            "        769,\n",
            "    ),\n",
            "    std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ],\n",
            "    type='SegDataPreProcessor')\n",
            "data_root = 'data/cityscapes/'\n",
            "dataset_type = 'CityscapesDataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(by_epoch=False, interval=100, type='CheckpointHook'),\n",
            "    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(draw=True, interval=100, type='SegVisualizationHook'))\n",
            "default_scope = 'mmseg'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_ratios = [\n",
            "    0.5,\n",
            "    0.75,\n",
            "    1.0,\n",
            "    1.25,\n",
            "    1.5,\n",
            "    1.75,\n",
            "]\n",
            "launcher = 'none'\n",
            "load_from = 'deeplabv3_r50b-d8_769x769_80k_cityscapes_20201225_155404-87fb0cf4.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=False)\n",
            "model = dict(\n",
            "    auxiliary_head=dict(\n",
            "        align_corners=True,\n",
            "        channels=256,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=1024,\n",
            "        in_index=2,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='SyncBN'),\n",
            "        num_classes=19,\n",
            "        num_convs=1,\n",
            "        type='FCNHead'),\n",
            "    backbone=dict(\n",
            "        contract_dilation=True,\n",
            "        depth=50,\n",
            "        dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            2,\n",
            "            4,\n",
            "        ),\n",
            "        norm_cfg=dict(requires_grad=True, type='SyncBN'),\n",
            "        norm_eval=False,\n",
            "        num_stages=4,\n",
            "        out_indices=(\n",
            "            0,\n",
            "            1,\n",
            "            2,\n",
            "            3,\n",
            "        ),\n",
            "        strides=(\n",
            "            1,\n",
            "            2,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        style='pytorch',\n",
            "        type='ResNetV1c'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_val=0,\n",
            "        seg_pad_val=255,\n",
            "        size=(\n",
            "            769,\n",
            "            769,\n",
            "        ),\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='SegDataPreProcessor'),\n",
            "    decode_head=dict(\n",
            "        align_corners=True,\n",
            "        channels=512,\n",
            "        dilations=(\n",
            "            1,\n",
            "            12,\n",
            "            24,\n",
            "            36,\n",
            "        ),\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=2048,\n",
            "        in_index=3,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='SyncBN'),\n",
            "        num_classes=19,\n",
            "        type='ASPPHead'),\n",
            "    pretrained='open-mmlab://resnet50_v1c',\n",
            "    test_cfg=dict(crop_size=(\n",
            "        769,\n",
            "        769,\n",
            "    ), mode='slide', stride=(\n",
            "        513,\n",
            "        513,\n",
            "    )),\n",
            "    train_cfg=dict(),\n",
            "    type='EncoderDecoder')\n",
            "norm_cfg = dict(requires_grad=True, type='SyncBN')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=None,\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=False,\n",
            "        end=80000,\n",
            "        eta_min=0.0001,\n",
            "        power=0.9,\n",
            "        type='PolyLR'),\n",
            "]\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        data_prefix=dict(\n",
            "            img_path='leftImg8bit/val', seg_map_path='gtFine/val'),\n",
            "        data_root='data/cityscapes/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                2049,\n",
            "                1025,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='CityscapesDataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mIoU',\n",
            "    ], type='IoUMetric')\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        2049,\n",
            "        1025,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "train_cfg = dict(max_iters=500, type='IterBasedTrainLoop', val_interval=500)\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    dataset=dict(\n",
            "        data_prefix=dict(\n",
            "            img_path='leftImg8bit/train', seg_map_path='gtFine/train'),\n",
            "        data_root='data/cityscapes/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(\n",
            "                keep_ratio=True,\n",
            "                ratio_range=(\n",
            "                    0.5,\n",
            "                    2.0,\n",
            "                ),\n",
            "                scale=(\n",
            "                    2049,\n",
            "                    1025,\n",
            "                ),\n",
            "                type='RandomResize'),\n",
            "            dict(\n",
            "                cat_max_ratio=0.75, crop_size=(\n",
            "                    769,\n",
            "                    769,\n",
            "                ), type='RandomCrop'),\n",
            "            dict(prob=0.5, type='RandomFlip'),\n",
            "            dict(type='PhotoMetricDistortion'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='CityscapesDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(\n",
            "        keep_ratio=True,\n",
            "        ratio_range=(\n",
            "            0.5,\n",
            "            2.0,\n",
            "        ),\n",
            "        scale=(\n",
            "            2049,\n",
            "            1025,\n",
            "        ),\n",
            "        type='RandomResize'),\n",
            "    dict(cat_max_ratio=0.75, crop_size=(\n",
            "        769,\n",
            "        769,\n",
            "    ), type='RandomCrop'),\n",
            "    dict(prob=0.5, type='RandomFlip'),\n",
            "    dict(type='PhotoMetricDistortion'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "tta_model = dict(type='SegTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
            "            ],\n",
            "            [\n",
            "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
            "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='LoadAnnotations'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        data_prefix=dict(\n",
            "            img_path='leftImg8bit/val', seg_map_path='gtFine/val'),\n",
            "        data_root='data/cityscapes/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                2049,\n",
            "                1025,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='CityscapesDataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mIoU',\n",
            "    ], type='IoUMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='SegLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/deeplabv3_r50-d8_4xb2-80k_cityscapes-769x769'\n",
            "\n",
            "/content/mmsegmentation/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use \"init_cfg\" instead\n",
            "  warnings.warn('DeprecationWarning: pretrained is a deprecated, '\n",
            "/content/mmsegmentation/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
            "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
            "/content/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
            "  warnings.warn(\n",
            "08/28 12:17:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "08/28 12:17:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "08/28 12:17:13 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
            "Loads checkpoint by local backend from path: deeplabv3_r50b-d8_769x769_80k_cityscapes_20201225_155404-87fb0cf4.pth\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: backbone.conv1.weight, backbone.bn1.weight, backbone.bn1.bias, backbone.bn1.running_mean, backbone.bn1.running_var, backbone.bn1.num_batches_tracked\n",
            "\n",
            "missing keys in source state_dict: backbone.stem.0.weight, backbone.stem.1.weight, backbone.stem.1.bias, backbone.stem.1.running_mean, backbone.stem.1.running_var, backbone.stem.3.weight, backbone.stem.4.weight, backbone.stem.4.bias, backbone.stem.4.running_mean, backbone.stem.4.running_var, backbone.stem.6.weight, backbone.stem.7.weight, backbone.stem.7.bias, backbone.stem.7.running_mean, backbone.stem.7.running_var\n",
            "\n",
            "08/28 12:17:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from deeplabv3_r50b-d8_769x769_80k_cityscapes_20201225_155404-87fb0cf4.pth\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "08/28 12:19:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [ 50/500]    eta: 0:22:11  time: 2.5474  data_time: 0.0066  memory: 8906  \n",
            "08/28 12:21:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [100/500]    eta: 0:18:14  time: 2.5160  data_time: 0.0067  memory: 905  \n",
            "08/28 12:23:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [150/500]    eta: 0:15:37  time: 2.5173  data_time: 0.0068  memory: 905  \n",
            "08/28 12:26:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [200/500]    eta: 0:13:12  time: 2.5203  data_time: 0.0065  memory: 905  \n",
            "08/28 12:28:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [250/500]    eta: 0:10:54  time: 2.5263  data_time: 0.0069  memory: 905  \n",
            "08/28 12:30:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [300/500]    eta: 0:08:40  time: 2.5183  data_time: 0.0068  memory: 905  \n",
            "08/28 12:32:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [350/500]    eta: 0:06:29  time: 2.5219  data_time: 0.0076  memory: 905  \n",
            "08/28 12:34:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [400/500]    eta: 0:04:18  time: 2.5225  data_time: 0.0072  memory: 905  \n",
            "08/28 12:36:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [450/500]    eta: 0:02:08  time: 2.5246  data_time: 0.0070  memory: 905  \n",
            "08/28 12:38:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [500/500]    eta: 0:00:00  time: 2.5171  data_time: 0.0063  memory: 905  \n",
            "08/28 12:38:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
            "08/28 12:38:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "+---------------+-------+-------+\n",
            "|     Class     |  IoU  |  Acc  |\n",
            "+---------------+-------+-------+\n",
            "|      road     | 62.24 | 68.72 |\n",
            "|    sidewalk   |  0.8  |  0.82 |\n",
            "|    building   | 22.76 | 27.25 |\n",
            "|      wall     |  0.62 |  1.57 |\n",
            "|     fence     |  0.11 |  0.13 |\n",
            "|      pole     |  2.21 |  2.62 |\n",
            "| traffic light |  0.01 |  0.01 |\n",
            "|  traffic sign |  0.0  |  0.0  |\n",
            "|   vegetation  |  0.8  |  0.84 |\n",
            "|    terrain    |  0.0  |  0.0  |\n",
            "|      sky      |  4.61 | 78.96 |\n",
            "|     person    |  0.09 |  0.09 |\n",
            "|     rider     |  0.0  |  0.0  |\n",
            "|      car      |  0.43 |  0.43 |\n",
            "|     truck     |  0.24 |  0.64 |\n",
            "|      bus      |  0.0  |  0.0  |\n",
            "|     train     |  0.0  |  0.0  |\n",
            "|   motorcycle  |  0.0  |  0.0  |\n",
            "|    bicycle    |  0.0  |  0.0  |\n",
            "+---------------+-------+-------+\n",
            "08/28 12:38:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [500/500]    aAcc: 34.7700  mIoU: 5.0000  mAcc: 9.5800  data_time: 0.0169  time: 2.5735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bonus - 75% compression"
      ],
      "metadata": {
        "id": "zm1urjnOFB-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python tools/train.py \\\n",
        "     configs/deeplabv3/deeplabv3_r50-d8_4xb2-80k_cityscapes-769x769.py \\\n",
        "     --cfg-options load_from=deeplabv3_r50b-d8_769x769_80k_cityscapes_20201225_155404-87fb0cf4.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yf34MUiYLui5",
        "outputId": "017b6cc7-26f8-4b0d-a53f-2001e7924129"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "08/28 12:47:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 195842166\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.1+cu118\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.8\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.7\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.2+cu118\n",
            "    OpenCV: 4.8.0\n",
            "    MMEngine: 0.8.4\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 195842166\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "08/28 12:47:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "crop_size = (\n",
            "    769,\n",
            "    769,\n",
            ")\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ],\n",
            "    pad_val=0,\n",
            "    seg_pad_val=255,\n",
            "    size=(\n",
            "        769,\n",
            "        769,\n",
            "    ),\n",
            "    std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ],\n",
            "    type='SegDataPreProcessor')\n",
            "data_root = 'data/cityscapes/'\n",
            "dataset_type = 'CityscapesDataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(by_epoch=False, interval=100, type='CheckpointHook'),\n",
            "    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(draw=True, interval=100, type='SegVisualizationHook'))\n",
            "default_scope = 'mmseg'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_ratios = [\n",
            "    0.5,\n",
            "    0.75,\n",
            "    1.0,\n",
            "    1.25,\n",
            "    1.5,\n",
            "    1.75,\n",
            "]\n",
            "launcher = 'none'\n",
            "load_from = 'deeplabv3_r50b-d8_769x769_80k_cityscapes_20201225_155404-87fb0cf4.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=False)\n",
            "model = dict(\n",
            "    auxiliary_head=dict(\n",
            "        align_corners=True,\n",
            "        channels=256,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=1024,\n",
            "        in_index=2,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='SyncBN'),\n",
            "        num_classes=19,\n",
            "        num_convs=1,\n",
            "        type='FCNHead'),\n",
            "    backbone=dict(\n",
            "        contract_dilation=True,\n",
            "        depth=50,\n",
            "        dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            2,\n",
            "            4,\n",
            "        ),\n",
            "        norm_cfg=dict(requires_grad=True, type='SyncBN'),\n",
            "        norm_eval=False,\n",
            "        num_stages=4,\n",
            "        out_indices=(\n",
            "            0,\n",
            "            1,\n",
            "            2,\n",
            "            3,\n",
            "        ),\n",
            "        strides=(\n",
            "            1,\n",
            "            2,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        style='pytorch',\n",
            "        type='ResNetV1c'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_val=0,\n",
            "        seg_pad_val=255,\n",
            "        size=(\n",
            "            769,\n",
            "            769,\n",
            "        ),\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='SegDataPreProcessor'),\n",
            "    decode_head=dict(\n",
            "        align_corners=True,\n",
            "        channels=512,\n",
            "        dilations=(\n",
            "            1,\n",
            "            12,\n",
            "            24,\n",
            "            36,\n",
            "        ),\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=2048,\n",
            "        in_index=3,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='SyncBN'),\n",
            "        num_classes=19,\n",
            "        type='ASPPHead'),\n",
            "    pretrained='open-mmlab://resnet50_v1c',\n",
            "    test_cfg=dict(crop_size=(\n",
            "        769,\n",
            "        769,\n",
            "    ), mode='slide', stride=(\n",
            "        513,\n",
            "        513,\n",
            "    )),\n",
            "    train_cfg=dict(),\n",
            "    type='EncoderDecoder')\n",
            "norm_cfg = dict(requires_grad=True, type='SyncBN')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=None,\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=False,\n",
            "        end=80000,\n",
            "        eta_min=0.0001,\n",
            "        power=0.9,\n",
            "        type='PolyLR'),\n",
            "]\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        data_prefix=dict(\n",
            "            img_path='leftImg8bit/val', seg_map_path='gtFine/val'),\n",
            "        data_root='data/cityscapes/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                2049,\n",
            "                1025,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='CityscapesDataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mIoU',\n",
            "    ], type='IoUMetric')\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        2049,\n",
            "        1025,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "train_cfg = dict(max_iters=500, type='IterBasedTrainLoop', val_interval=500)\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    dataset=dict(\n",
            "        data_prefix=dict(\n",
            "            img_path='leftImg8bit/train', seg_map_path='gtFine/train'),\n",
            "        data_root='data/cityscapes/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(\n",
            "                keep_ratio=True,\n",
            "                ratio_range=(\n",
            "                    0.5,\n",
            "                    2.0,\n",
            "                ),\n",
            "                scale=(\n",
            "                    2049,\n",
            "                    1025,\n",
            "                ),\n",
            "                type='RandomResize'),\n",
            "            dict(\n",
            "                cat_max_ratio=0.75, crop_size=(\n",
            "                    769,\n",
            "                    769,\n",
            "                ), type='RandomCrop'),\n",
            "            dict(prob=0.5, type='RandomFlip'),\n",
            "            dict(type='PhotoMetricDistortion'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='CityscapesDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(\n",
            "        keep_ratio=True,\n",
            "        ratio_range=(\n",
            "            0.5,\n",
            "            2.0,\n",
            "        ),\n",
            "        scale=(\n",
            "            2049,\n",
            "            1025,\n",
            "        ),\n",
            "        type='RandomResize'),\n",
            "    dict(cat_max_ratio=0.75, crop_size=(\n",
            "        769,\n",
            "        769,\n",
            "    ), type='RandomCrop'),\n",
            "    dict(prob=0.5, type='RandomFlip'),\n",
            "    dict(type='PhotoMetricDistortion'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "tta_model = dict(type='SegTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
            "            ],\n",
            "            [\n",
            "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
            "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='LoadAnnotations'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        data_prefix=dict(\n",
            "            img_path='leftImg8bit/val', seg_map_path='gtFine/val'),\n",
            "        data_root='data/cityscapes/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                2049,\n",
            "                1025,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='CityscapesDataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mIoU',\n",
            "    ], type='IoUMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='SegLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/deeplabv3_r50-d8_4xb2-80k_cityscapes-769x769'\n",
            "\n",
            "/content/mmsegmentation/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use \"init_cfg\" instead\n",
            "  warnings.warn('DeprecationWarning: pretrained is a deprecated, '\n",
            "/content/mmsegmentation/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
            "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
            "/content/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
            "  warnings.warn(\n",
            "08/28 12:47:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "08/28 12:47:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "08/28 12:47:36 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
            "08/28 12:47:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: open-mmlab://resnet50_v1c\n",
            "08/28 12:47:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by openmmlab backend from path: open-mmlab://resnet50_v1c\n",
            "Downloading: \"https://download.openmmlab.com/pretrain/third_party/resnet50_v1c-2cccc1ad.pth\" to /root/.cache/torch/hub/checkpoints/resnet50_v1c-2cccc1ad.pth\n",
            "100% 97.8M/97.8M [00:00<00:00, 128MB/s]\n",
            "08/28 12:47:38 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: fc.weight, fc.bias\n",
            "\n",
            "Loads checkpoint by local backend from path: deeplabv3_r50b-d8_769x769_80k_cityscapes_20201225_155404-87fb0cf4.pth\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: backbone.conv1.weight, backbone.bn1.weight, backbone.bn1.bias, backbone.bn1.running_mean, backbone.bn1.running_var, backbone.bn1.num_batches_tracked\n",
            "\n",
            "missing keys in source state_dict: backbone.stem.0.weight, backbone.stem.1.weight, backbone.stem.1.bias, backbone.stem.1.running_mean, backbone.stem.1.running_var, backbone.stem.3.weight, backbone.stem.4.weight, backbone.stem.4.bias, backbone.stem.4.running_mean, backbone.stem.4.running_var, backbone.stem.6.weight, backbone.stem.7.weight, backbone.stem.7.bias, backbone.stem.7.running_mean, backbone.stem.7.running_var\n",
            "\n",
            "08/28 12:47:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from deeplabv3_r50b-d8_769x769_80k_cityscapes_20201225_155404-87fb0cf4.pth\n",
            "08/28 12:47:38 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "08/28 12:47:38 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "08/28 12:47:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /content/mmsegmentation/work_dirs/deeplabv3_r50-d8_4xb2-80k_cityscapes-769x769.\n",
            "08/28 12:50:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 50/500]  lr: 9.9945e-03  eta: 0:29:48  time: 2.1851  data_time: 0.0075  memory: 11043  loss: 1.8532  decode.loss_ce: 1.2880  decode.acc_seg: 56.1503  aux.loss_ce: 0.5652  aux.acc_seg: 62.9249\n",
            "08/28 12:52:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [100/500]  lr: 9.9890e-03  eta: 0:20:32  time: 2.1878  data_time: 0.0073  memory: 6561  loss: 1.7478  decode.loss_ce: 1.1806  decode.acc_seg: 47.8441  aux.loss_ce: 0.5672  aux.acc_seg: 56.3582\n",
            "08/28 12:52:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 100 iterations\n",
            "08/28 12:54:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [150/500]  lr: 9.9834e-03  eta: 0:16:30  time: 2.1918  data_time: 0.0075  memory: 6562  loss: 1.6358  decode.loss_ce: 1.1121  decode.acc_seg: 56.3290  aux.loss_ce: 0.5237  aux.acc_seg: 48.0044\n",
            "08/28 12:56:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [200/500]  lr: 9.9778e-03  eta: 0:13:21  time: 2.1903  data_time: 0.0077  memory: 6562  loss: 1.4113  decode.loss_ce: 0.9264  decode.acc_seg: 77.7960  aux.loss_ce: 0.4850  aux.acc_seg: 50.0933\n",
            "08/28 12:56:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 200 iterations\n",
            "08/28 12:58:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [250/500]  lr: 9.9723e-03  eta: 0:10:47  time: 2.1893  data_time: 0.0077  memory: 6561  loss: 1.5046  decode.loss_ce: 1.0177  decode.acc_seg: 62.0454  aux.loss_ce: 0.4869  aux.acc_seg: 53.8536\n",
            "08/28 13:00:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [300/500]  lr: 9.9667e-03  eta: 0:08:24  time: 2.1912  data_time: 0.0070  memory: 6562  loss: 1.4844  decode.loss_ce: 0.9946  decode.acc_seg: 71.3690  aux.loss_ce: 0.4898  aux.acc_seg: 62.3493\n",
            "08/28 13:00:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 300 iterations\n",
            "08/28 13:02:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [350/500]  lr: 9.9611e-03  eta: 0:06:13  time: 2.1893  data_time: 0.0072  memory: 6561  loss: 1.8097  decode.loss_ce: 1.2179  decode.acc_seg: 62.7601  aux.loss_ce: 0.5918  aux.acc_seg: 57.3284\n",
            "08/28 13:03:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [400/500]  lr: 9.9555e-03  eta: 0:04:05  time: 2.1937  data_time: 0.0086  memory: 6562  loss: 1.6613  decode.loss_ce: 1.1242  decode.acc_seg: 59.6134  aux.loss_ce: 0.5371  aux.acc_seg: 42.7729\n",
            "08/28 13:03:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 400 iterations\n",
            "08/28 13:05:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [450/500]  lr: 9.9500e-03  eta: 0:02:01  time: 2.1911  data_time: 0.0081  memory: 6562  loss: 1.5760  decode.loss_ce: 1.0656  decode.acc_seg: 78.0524  aux.loss_ce: 0.5104  aux.acc_seg: 71.1431\n",
            "08/28 13:07:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [500/500]  lr: 9.9444e-03  eta: 0:00:00  time: 2.1948  data_time: 0.0072  memory: 6562  loss: 1.3938  decode.loss_ce: 0.9398  decode.acc_seg: 57.5723  aux.loss_ce: 0.4540  aux.acc_seg: 61.0573\n",
            "08/28 13:07:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 500 iterations\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "08/28 13:10:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [ 50/500]    eta: 0:21:52  time: 2.5072  data_time: 0.0072  memory: 9168  \n",
            "08/28 13:12:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/500]    eta: 0:18:03  time: 2.5045  data_time: 0.0072  memory: 1165  \n",
            "08/28 13:14:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [150/500]    eta: 0:15:26  time: 2.5011  data_time: 0.0062  memory: 1165  \n",
            "08/28 13:16:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [200/500]    eta: 0:13:03  time: 2.5106  data_time: 0.0076  memory: 1165  \n",
            "08/28 13:18:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [250/500]    eta: 0:10:48  time: 2.5044  data_time: 0.0068  memory: 1165  \n",
            "08/28 13:20:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [300/500]    eta: 0:08:35  time: 2.5115  data_time: 0.0067  memory: 1165  \n",
            "08/28 13:22:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [350/500]    eta: 0:06:25  time: 2.4973  data_time: 0.0065  memory: 1165  \n",
            "08/28 13:24:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [400/500]    eta: 0:04:16  time: 2.5028  data_time: 0.0073  memory: 1165  \n",
            "08/28 13:26:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [450/500]    eta: 0:02:07  time: 2.4992  data_time: 0.0061  memory: 1165  \n",
            "08/28 13:29:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [500/500]    eta: 0:00:00  time: 2.4976  data_time: 0.0068  memory: 1165  \n",
            "08/28 13:29:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
            "08/28 13:29:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "+---------------+-------+-------+\n",
            "|     Class     |  IoU  |  Acc  |\n",
            "+---------------+-------+-------+\n",
            "|      road     | 80.94 | 97.28 |\n",
            "|    sidewalk   | 10.47 | 16.73 |\n",
            "|    building   | 45.77 | 56.69 |\n",
            "|      wall     |  0.0  |  0.0  |\n",
            "|     fence     |  0.0  |  0.0  |\n",
            "|      pole     |  0.0  |  0.0  |\n",
            "| traffic light |  0.0  |  0.0  |\n",
            "|  traffic sign |  3.73 |  4.05 |\n",
            "|   vegetation  | 56.28 | 88.95 |\n",
            "|    terrain    |  0.0  |  0.0  |\n",
            "|      sky      | 55.67 | 95.94 |\n",
            "|     person    |  1.54 |  1.63 |\n",
            "|     rider     |  0.0  |  0.0  |\n",
            "|      car      | 20.55 | 24.12 |\n",
            "|     truck     |  0.0  |  0.0  |\n",
            "|      bus      |  0.0  |  0.0  |\n",
            "|     train     |  0.0  |  0.0  |\n",
            "|   motorcycle  |  0.0  |  0.0  |\n",
            "|    bicycle    |  0.02 |  0.02 |\n",
            "+---------------+-------+-------+\n",
            "08/28 13:29:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [500/500]    aAcc: 70.2000  mIoU: 14.4700  mAcc: 20.2800  data_time: 0.0151  time: 2.5500\n"
          ]
        }
      ]
    }
  ]
}